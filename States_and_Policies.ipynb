{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd25408",
   "metadata": {},
   "source": [
    "# States and Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6ec44",
   "metadata": {},
   "source": [
    "## Description of Notebook\n",
    "In this Notebook we will create the states for the Job Scheduling Problem in the deterministic case.<br>\n",
    "We will define the class of states and give a function to compute every state.<br>\n",
    "To be able to feed them into a Neural Network later on, we will add a compatible representation of their information as data for the input.<br>\n",
    "Since we approach this problem from the perspective of Deep Q-Learning, their can be taken an action in every non-final state, leading to one of the successor states. Therefore, every state needs a Q-value for every corresponding action that is possible. Either these Q-Values or the corresponding one-hot-vector indicating the optimal action will then become the target-vector.<br>\n",
    "Finally, we will define a composite function executing all these steps.<br>\n",
    "From here on, it is easy to compute Policies, including the Optimal Policy. A function herefore for will be given as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623dac43",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ecc4a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Jobs_and_Machines.ipynb\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import operator\n",
    "import random\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "import import_ipynb\n",
    "from Jobs_and_Machines import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b592409",
   "metadata": {},
   "source": [
    "### Class of States\n",
    "The idea is that the Machines will be processing the Jobs. Whenever a Job finishes, a Machine gets free and therefore an action has to be taken. This situation will be given in the form of a State.<br>\n",
    "Possible actions in this state are to assign a new Job to a Machine or to shut the free Machine down, which means it cannot be used anymore from here on.<br>\n",
    "If all Jobs have been assigned and/or processed already, the state is final and no decision has to be taken.<br>\n",
    "To save computing time, for the case that more than one Machine is free at some point we will always only use the free Machine with the lowest index. After having taken an action on it, it is not free anymore and we move to the next state, which will happen to have the same time, to take care of the next free Machine.\n",
    "<br>This approach could lead to splitting the Reinforcement Learning Problem into several ones, having one agent for every Machine. However, when passing the information about the state to the Neural Network, we will also pass the information of which Machines are free in this state to counteract the mentioned tendency. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e454352a",
   "metadata": {},
   "source": [
    "A State consists of these environmental information:\n",
    "\n",
    "   1. The Jobs and Machines of the Job Scheduling Problem it belongs to\n",
    "   2. Time\n",
    "   3. Remaining Jobs\n",
    "   4. Machines that are still on duty\n",
    "   5. Free Machines\n",
    "   6. Remaining processing time of occupated Machines\n",
    "   7. Which Machine is working on which Job\n",
    "    \n",
    "The State also needs information about how it is related to other States:\n",
    "   1. ID of State\n",
    "   2. Predecessor State\n",
    "   3. Action that led to this state\n",
    "   4. Transition Costs from predecessor to current State\n",
    "   5. The machine that will be used\n",
    "   6. A dictionary mapping every action to the corresponding succesor states as well as a list of all successor States\n",
    "   7. Optimal Future Costs for every action (Q-Values)\n",
    "   \n",
    "Finally, it needs its information stored as data that the Neural Network can process:\n",
    "   1. Input\n",
    "   2. Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da7a8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class states:\n",
    "    def __init__(self, time, jobs_remaining, machines_on_duty,\n",
    "                 free_machines, machine_runtimes, machine_occupations, predecessor):\n",
    "        \n",
    "        #job scheduling problem environment\n",
    "        self.jobs = list_jobs\n",
    "        self.machines = list_machines\n",
    "        \n",
    "        #time\n",
    "        self.time = time\n",
    "        \n",
    "        #information about the jobs\n",
    "        self.jobs_remaining = jobs_remaining #\"one\" if job is still remaining, \"zero\" if it was assigned already\n",
    "        \n",
    "        #information about the machines\n",
    "        self.machines_on_duty = machines_on_duty #\"one\" if machine is still on duty, \"zero\" if it was shut down already\n",
    "        self.free_machines = free_machines #\"one\" if machine is free, \"zero\" if it is occupied or shut down\n",
    "        self.machine_runtimes = machine_runtimes #remaining runtime of every machine\n",
    "        self.machine_occupations = machine_occupations #which machine is working on which job\n",
    "        \n",
    "        #predecessor and successors\n",
    "        self.ID = None #ID of the state, will be given after all states were created\n",
    "        self.predecessor = predecessor #what was the predecessor state\n",
    "        self.machine = None\n",
    "        self.successors = None #the successor states will be added when creating the entire tree of states\n",
    "        \n",
    "        #costs and actions\n",
    "        self.costs = None #cost to transition from the predecessor state to the current one\n",
    "        self.action = (None, None) #action to transition from the predecessor state to the current one\n",
    "        self.transition_dic = {}\n",
    "        \n",
    "        #optimal future costs\n",
    "            #will be added after all states were created\n",
    "            #list of length n+1 (n is number oj jobs)\n",
    "            #the entry on row i stands for the optimal future costs to assign job i to the chosen machine\n",
    "            #last row stands for turning off a machine\n",
    "        self.Qvalues = [None]*(n+1)\n",
    "        \n",
    "        #data for Neural Network\n",
    "        self.input = None\n",
    "        self.target = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6942d2a8",
   "metadata": {},
   "source": [
    "### Creation of all States\n",
    "We will now define all the necessary functions so that all the states can be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84128e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create every possible state\n",
    "def create_all_states(list_jobs,list_machines):\n",
    "    \n",
    "    #initiate list of states = []\n",
    "    list_states = []\n",
    "    \n",
    "    #create initial state\n",
    "    initial_state = create_initial_state()\n",
    "    ID = 0\n",
    "    \n",
    "    #list of current states\n",
    "    current_states = [initial_state]\n",
    "    \n",
    "    #go through every current state, save their successors, add current states to list of all states\n",
    "        #then define successor states as current states, clear list of successor states and repeat until done\n",
    "    while current_states:\n",
    "        \n",
    "        #empty list of all successor states\n",
    "        successor_states = []\n",
    "        \n",
    "        #create and add all successor states of current states\n",
    "        for state in current_states:\n",
    "            \n",
    "            #give ID\n",
    "            state.ID = ID\n",
    "            ID += 1\n",
    "            \n",
    "            #list of all successors of this state\n",
    "            state_successors = []\n",
    "            \n",
    "            #check if we are already in a final state\n",
    "            if sum(state.jobs_remaining) == 0:\n",
    "                #add remaining costs until everything is finished, if that is not the case yet\n",
    "                if state.machine_runtimes:\n",
    "                    state.costs += max(state.machine_runtimes)\n",
    "                \n",
    "            #create one state for every remaining job assigned to the free machine with lowest index\n",
    "            else:\n",
    "                \n",
    "                #get free machine with lowest index as object\n",
    "                machine = list_machines[state.free_machines.index(1)]\n",
    "                state.machine = machine.index\n",
    "                \n",
    "                #create data for Neural Network\n",
    "                state_to_data(state)\n",
    "                    \n",
    "                #loop through jobs\n",
    "                list_jobs_remaining = [job for job in list_jobs if state.jobs_remaining[job.index] == 1]\n",
    "                for index, job in enumerate(list_jobs):\n",
    "                    #check if the job still has to be done\n",
    "                    if state.jobs_remaining[index] == 1:\n",
    "                        #assign job to machine\n",
    "                        state_successors.append(assign_job(state,job,machine))    \n",
    "                \n",
    "                #check if turning it off is an option\n",
    "                if sum(state.machines_on_duty) > 1:                       \n",
    "                    #add successor state created by shutting down machine\n",
    "                    state_successors.append(turn_off_machine(state, machine))\n",
    "                        \n",
    "                \n",
    "            #add successor list to the attributes of state\n",
    "            state.successors = state_successors\n",
    "            \n",
    "            #add successors of this state to the list of all successors of all current states\n",
    "            successor_states += state_successors\n",
    "        \n",
    "        #add current states to list of all states\n",
    "        list_states += current_states\n",
    "        \n",
    "        #the successor states then become the current states\n",
    "        current_states = successor_states\n",
    "        \n",
    "    return list_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e79440bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the initial state\n",
    "def create_initial_state():\n",
    "    \n",
    "    #create initial circumstances\n",
    "    time = 0\n",
    "    jobs_remaining = [1]*n\n",
    "    machines_on_duty = [1]*m\n",
    "    machine_runtimes = [machine.init_runtime for machine in list_machines]\n",
    "    machine_occupations = [None if x==0 else -1 for x in machine_runtimes] # \"-1\" stands for an initial occupation\n",
    "    free_machines = [1 if x==0 else 0 for x in machine_runtimes]\n",
    "    \n",
    "    #create initial state\n",
    "    initial_state = states(time, jobs_remaining, machines_on_duty, free_machines, machine_runtimes, machine_occupations, None)\n",
    "    initial_state.costs = initialize_costs(initial_state)\n",
    "    \n",
    "    return initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "811b8943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_job(state,job,machine):\n",
    "    \n",
    "    #job gets canceled from to-do-list\n",
    "    jobs_remaining = state.jobs_remaining.copy()\n",
    "    jobs_remaining[job.index] = 0\n",
    "    \n",
    "    #machine is not free anymore\n",
    "    free_machines = state.free_machines.copy()\n",
    "    free_machines[machine.index] = 0\n",
    "    \n",
    "    #it gets a runtime equivalent to the jobs processing time\n",
    "    machine_runtimes = state.machine_runtimes.copy()\n",
    "    machine_runtimes[machine.index] = job.processing_time [machine.index]\n",
    "    \n",
    "    #we assign this job to the machine\n",
    "    machine_occupations = state.machine_occupations.copy()\n",
    "    machine_occupations[machine.index] = job.index \n",
    "    \n",
    "    #if there is another free machine, we create a successor state at same time\n",
    "    if sum(free_machines) > 0:\n",
    "        #no time passes\n",
    "        time_difference = 0\n",
    "        #create state\n",
    "        successor_state = states(state.time, jobs_remaining, state.machines_on_duty,\n",
    "                                 free_machines, machine_runtimes, machine_occupations, state)\n",
    "    \n",
    "    #elsewise we have to proceed to the point where the next job finishes\n",
    "    else:\n",
    "        #calculate new time for when next job finishes\n",
    "        time_difference = min([runtime for runtime in machine_runtimes if runtime > 0])\n",
    "        new_time = state.time + time_difference\n",
    "                            \n",
    "        #the following machine(s) become free\n",
    "        for index in range(m):\n",
    "            if machine_runtimes[index] == time_difference:\n",
    "                free_machines[index] = 1\n",
    "                machine_occupations[index] = None\n",
    "                            \n",
    "        #update machine runtimes\n",
    "        machine_runtimes = [max(runtime - time_difference,0) for runtime in machine_runtimes]\n",
    "                            \n",
    "        #create succesor state\n",
    "        successor_state = states(new_time, jobs_remaining, state.machines_on_duty,\n",
    "                                 free_machines, machine_runtimes, machine_occupations, state)\n",
    "        \n",
    "    #give its action and costs\n",
    "    successor_state.action = (job.index,machine.index)\n",
    "    successor_state.costs = transition_costs(state,successor_state,job,machine)\n",
    "\n",
    "        \n",
    "    #add successor state to transition dictionary\n",
    "    state.transition_dic[(job.index,machine.index)] = successor_state    \n",
    "    \n",
    "    return successor_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e44ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create all successors of a state by shutting down machine\n",
    "def turn_off_machine(state, machine):\n",
    "    \n",
    "    #machine gets shut down\n",
    "    machines_on_duty = state.machines_on_duty.copy()\n",
    "    machines_on_duty[machine.index] = 0\n",
    "                        \n",
    "    #machine is not free anymore\n",
    "    free_machines = state.free_machines.copy()\n",
    "    free_machines[machine.index] = 0                              \n",
    "                        \n",
    "    #if there is another free machine, we create a successor state at same time\n",
    "    if sum(free_machines) > 0:\n",
    "        #no time passes\n",
    "        time_difference = 0\n",
    "        #create state\n",
    "        successor_state = states(state.time, state.jobs_remaining, machines_on_duty,\n",
    "                                 free_machines, state.machine_runtimes, state.machine_occupations, state)\n",
    "        \n",
    "    #elsewise we have to proceed to the point where the next job finishes\n",
    "    else:\n",
    "        #calculate new time for when next job finishes\n",
    "        time_difference = min([runtime for runtime in state.machine_runtimes if runtime > 0])\n",
    "        new_time = state.time + time_difference\n",
    "                            \n",
    "        #the following machine(s) become free\n",
    "        machine_occupations = state.machine_occupations.copy()\n",
    "        for index in range(m):\n",
    "            if state.machine_runtimes[index] == time_difference:\n",
    "                free_machines[index] = 1\n",
    "                machine_occupations[index] = None\n",
    "                            \n",
    "        #update machine runtimes\n",
    "        machine_runtimes = [max(runtime - time_difference,0) for runtime in state.machine_runtimes]\n",
    "                            \n",
    "        #create succesor state\n",
    "        successor_state = states(new_time, state.jobs_remaining, machines_on_duty,\n",
    "                                 free_machines, machine_runtimes, machine_occupations, state)\n",
    "        \n",
    "    #give its action and costs\n",
    "    successor_state.action = (n,machine.index)\n",
    "    successor_state.costs = transition_costs(state,successor_state,None,machine)\n",
    "        \n",
    "        \n",
    "    #add successor state to transition dictionary\n",
    "    state.transition_dic[(n,machine.index)] = successor_state\n",
    "        \n",
    "    return successor_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cf9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_costs(initial_state):\n",
    "    \n",
    "    costs = 0\n",
    "    for i, runtime in enumerate(initial_state.machine_runtimes):\n",
    "        machine = list_machines[i]\n",
    "        costs += max(0,machine.weight*(runtime - machine.deadline))\n",
    "        \n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0c5c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_costs(state, successor_state, job, machine):\n",
    "    \n",
    "    #runtime costs (time passing + deadline cost of idle jobs)\n",
    "    st = state.time #start time\n",
    "    nt = successor_state.time #next time\n",
    "    transition_costs = nt - st #cost of time passing\n",
    "    #jobs can be idle, therefore deadline costs might have to be payed while waiting for next state\n",
    "    for i, job_i in enumerate(list_jobs):\n",
    "        if successor_state.jobs_remaining[i] == 1: #check if job has been assigned already\n",
    "            transition_costs += max(0, job_i.weight*(nt-max(job_i.deadline,st)))   \n",
    "    \n",
    "    #deadline costs (if job was assigned/state is not a machine turn-off state)\n",
    "    if job:\n",
    "        proc_time = job.processing_time[machine.index]\n",
    "        ct = st + proc_time #completion time\n",
    "        transition_costs += max(0,job.weight*(ct - max(job.deadline,st))) #job deadline overdue costs\n",
    "        transition_costs += max(0,machine.weight*(ct - max(machine.deadline,st))) #machine deadline overdue costs\n",
    "\n",
    "    return transition_costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41146933",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We want to turn the information of every state into a data type that we can feed into our Neural Network.\n",
    "To interprete the states as feedable Data, we need them to contain the following information accessible and compatible for a Neural Network:\n",
    "\n",
    "- Matrix of Jobs (row-wise): Runtime per Machine, Time until Deadline and Weight.\n",
    "- Matrix of Machines (row-wise): Remaining Runtime of Machine, Time until Deadline and Weights.\n",
    "- Target: Vector of Q-Values. If an action is non-feasible it gets value zero and will be canceled out in the Neural Network later. Also the corresponding one-hot-vector indicating the optimal action.\n",
    "\n",
    "Finally, we flat out the matrices and normalize the Runtimes by the given Maximal Processing Time, the times until Deadline by the Maximal Deadline and the Weights by the Maximal Weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f62f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take information of state to create normalized data for Neural Network\n",
    "def state_to_data(state):\n",
    "    \n",
    "    #normalized information about the jobs\n",
    "    jobs_data = np.asarray([[(proc_time/max_runtime) for i, proc_time in enumerate(job.processing_time)\n",
    "                             if state.machines_on_duty[i] == 1]\n",
    "                            + [max(job.deadline-state.time,0)/max_deadline,\n",
    "                               job.weight/max_weight]\n",
    "                            for job in list_jobs if state.jobs_remaining[job.index] == 1])\n",
    "    \n",
    "    #normalized information about the machines\n",
    "    machines_data = np.asarray([[state.machine_runtimes[machine.index]/max_runtime,\n",
    "                                 max(machine.deadline-state.time,0)/max_deadline,\n",
    "                                 machine.weight/max_weight] \n",
    "                                for machine in list_machines if state.machines_on_duty[machine.index] == 1])\n",
    "                             \n",
    "    #sort them and save permutation\n",
    "    machines_perm = machines_data[:,0].argsort() #sort machines by remaining runtime\n",
    "    orig_order = np.arange(len(machines_perm)) #just an array of the form [0,1,...,m_state-1]\n",
    "    jobs_data[:,orig_order] = jobs_data[:,machines_perm] #reorder processing time of jobs by new order of machines\n",
    "    jobs_perm = jobs_data[:,0].argsort() #order of jobs by processing time for current free machine\n",
    "    jobs_data = jobs_data[jobs_perm] #sort jobs by this order\n",
    "    machines_data = machines_data[machines_perm] #sort machines by their remaining runtime\n",
    "    \n",
    "    #merge\n",
    "    state.input = [jobs_data, machines_data]\n",
    "    state.permutation = [jobs_perm,machines_perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bdfed1",
   "metadata": {},
   "source": [
    "### Q-Values\n",
    "We will now define the functions that compute the Q-Values for every action from every State.\n",
    "As soon as the Q-Values of a state are computed, we add them as as target vector, replacing the \"None\" -entries with zero to be compatible for the Neural Network later on, where these zero-values referring to non-feasible action will get cancelled out. We also add the corresponding one-hot-vector indication the optimal action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27e8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find Q-values of every state by backtracking\n",
    "def backtracking(all_states):\n",
    "    \n",
    "    #new list of all states that have already been backtracked completely\n",
    "    backtracked_states = []\n",
    "    #list of states that yet have to be backtracked\n",
    "    states_to_backtrack = all_states.copy()\n",
    "    \n",
    "    for state in states_to_backtrack:\n",
    "        #how many successors of this node have already been backtracked\n",
    "        state.backtracking = - len(state.successors) #we will count upwards until zero\n",
    "                \n",
    "    while states_to_backtrack:\n",
    "        #states that are temporary final in regard to backtracking (all their successors have backtracked already)\n",
    "        temp_final_states = []\n",
    "        \n",
    "        #sort list, so we can pop all nodes that are temporary final in every step\n",
    "        states_to_backtrack.sort(key=operator.attrgetter('backtracking'))\n",
    "        for state in states_to_backtrack[::-1]:\n",
    "            if state.backtracking == 0:\n",
    "                temp_final_states.append(states_to_backtrack.pop())\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        #add values of temporary final states to the optimal future costs of their predecessors at its place for this action\n",
    "        for state in temp_final_states:\n",
    "            predecessor = state.predecessor\n",
    "            #define target vector corresponding to Q-Values and One-Hot-Vector indicating optimal decision in permutaded order\n",
    "            n_state = sum(state.jobs_remaining)\n",
    "            if n_state > 0:\n",
    "                #get Qvalues of all feasible actions\n",
    "                target = np.array([qvalue for qvalue in state.Qvalues if qvalue != None])\n",
    "                #sort by permutation\n",
    "                target[np.arange(n_state)] = target[state.permutation[0]]\n",
    "                state.target = [target, \n",
    "                                np.eye(target.shape[0])[np.argmin(target)], #one_hot_vector of optimal action\n",
    "                               np.min(target)/target] #normalize by scaling through minimum value and then taking inverse value\n",
    "            #stop when there is no predecessor anymore\n",
    "            if not predecessor:\n",
    "                break\n",
    "            #add optimal future costs at position of action\n",
    "            predecessor.Qvalues[state.action[0]] = state.costs + minimum(state)[0]\n",
    "            #count upwards of how many successors this state still needs its Q-value before becoming temporary final itself\n",
    "            predecessor.backtracking += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e442b36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the minimum Qvalue and its belonging action from a state\n",
    "def minimum(state):\n",
    "    minimum = None\n",
    "    job = None\n",
    "\n",
    "    for i, val in enumerate(state.Qvalues):\n",
    "        if val != None:\n",
    "            if minimum == None:\n",
    "                minimum = val\n",
    "                job = i\n",
    "            elif val < minimum:\n",
    "                minimum = val\n",
    "                job = i\n",
    "    \n",
    "    #final states have no successors, so we set all future costs to zero\n",
    "    if minimum == None:\n",
    "        minimum = 0\n",
    "    \n",
    "    action = (job,state.machine)\n",
    "        \n",
    "    return minimum, action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef4961d",
   "metadata": {},
   "source": [
    "### Computation of all states\n",
    "We merge now all of our former results into one single function that shall compute all possible states together with all of their Q-Values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b33580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the entire process from creation of all states to updating their Qvalues by backtracking\n",
    "def compute_all_states(jobs, machines, max_r, max_d, max_w, MVS=0, JS=0, save=False, name=\"all_states\"):\n",
    "    \n",
    "    #define global parameters for easier access\n",
    "    global list_jobs, list_machines, n,m#, jobs_data, machines_data\n",
    "    list_jobs, list_machines = jobs, machines\n",
    "    n, m = len(jobs), len(machines)\n",
    "    global max_runtime, max_deadline, max_weight\n",
    "    max_runtime, max_deadline, max_weight = max_r, max_d, max_w\n",
    "    \n",
    "    #measure starting time\n",
    "    st = time.time()\n",
    "    \n",
    "    #create all states\n",
    "    all_states = create_all_states(list_jobs,list_machines)\n",
    "    \n",
    "    #update their Qvalues by backtracking\n",
    "    backtracking(all_states)\n",
    "    \n",
    "    #save the computed states\n",
    "    if save:\n",
    "        path = f'{name}.pickle'\n",
    "    else:\n",
    "        MVS_str = \"0\"*(2-len(str(MVS))) + str(MVS)\n",
    "        JS_str = \"0\"*(4-len(str(JS))) + str(JS)\n",
    "        path = f'MaxValuesSets/MaxValues_{MVS_str}/JobScheduling_{JS_str}/all_states_{MVS_str}_{JS_str}.pickle'\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(all_states, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    \n",
    "    #measure end time\n",
    "    et = time.time()\n",
    "    \n",
    "    #tell how much time the entire process took\n",
    "    print(round(et-st,2), \"seconds to compute\", len(all_states), \"states.\")\n",
    "    \n",
    "    if save:\n",
    "        return(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17074206",
   "metadata": {},
   "source": [
    "### Policies\n",
    "Having created all the states and the Q-Values corresponding to each of their actions, we can now create Policies.<br>\n",
    "A Policy is a tuple an consist of the list of all actions and a list of all States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb29c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute random policy\n",
    "def random_policy(all_states):\n",
    "    \n",
    "    #initial state\n",
    "    rand_state = all_states[0]\n",
    "    \n",
    "    random_actions = []\n",
    "    random_states = [rand_state]\n",
    "    \n",
    "    while rand_state.successors:\n",
    "        #choose a random successor state\n",
    "        rand_successor = random.choice(rand_state.successors)\n",
    "        #add this random action and state to policy\n",
    "        random_actions.append(rand_successor.action)\n",
    "        random_states.append(rand_successor)\n",
    "        #continue policy from this state\n",
    "        rand_state = rand_successor\n",
    "        \n",
    "    return random_actions, random_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99fa4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute optimal policy\n",
    "def optimal_policy(all_states, name=\"optimal_policy\"):\n",
    "    \n",
    "    initial_state = all_states[0]\n",
    "    optimal_actions = []\n",
    "    optimal_states = []\n",
    "    state = initial_state\n",
    "    \n",
    "    #go down the tree, always choosing the successor with the minimal Q-value\n",
    "    while state.successors:\n",
    "        #add state\n",
    "        optimal_states.append(state)\n",
    "        #add action\n",
    "        optimal_action = minimum(state)[1]\n",
    "        optimal_actions.append(optimal_action)\n",
    "        #declare the successor\n",
    "        for successor in state.successors:\n",
    "            if successor.action == optimal_action:\n",
    "                state = successor\n",
    "    \n",
    "    #add final state            \n",
    "    optimal_states.append(state)\n",
    "    \n",
    "    #safe optimal policy\n",
    "    with open(f'{name}.pickle', 'wb') as f:\n",
    "        pickle.dump((optimal_actions,optimal_states), f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return optimal_actions,optimal_states"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
